{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show caseon training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "sys.path.append('../')\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import emcee\n",
    "from delight.io import *\n",
    "from delight.utils import *\n",
    "from delight.utils_cy import approx_flux_likelihood_cy\n",
    "from delight.photoz_gp import PhotozGP\n",
    "from delight.photoz_kernels import Photoz_mean_function, Photoz_kernel\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAABECAYAAACmlnyPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAACZ0lEQVR4nO3aIW5UURiG4VtKK8Y0GQGBITUUDCCKGccOUCC6BlSTLgHNAkgIKBQGh6TBXV2NIGQEKQSShlS06WUB0447838Znkf+x3zyFWdtGIahAwCAQNeqBwAAwFXEKgAAscQqAACxxCoAALHEKgAAsa4verz7cLc7H42XtWXpHm1+rZ7Q1NH6jeoJzTw4+VE9oamLjfvVE9ra+FW9oKnR5qR6QlPHZ3+qJzQ13vpZPaGZb6f3qic09fvkb/WEpla9W47PbnZ938/dF8bq+WjcfX+y32pTucM7z6onNLWz9bx6QjOfDl9VT2jq9Pbb6glNXdx6Xz2hqd3tl9UTmno9+1g9oam9p++qJzTz4uhN9YSmPnyeD51VsurdcvDl8aV33wAAAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiLU2DMNw1eN0Ou0mk8ky9wAA8B+azWZd3/dz94WxCgAAlXwDAAAgllgFACCWWAUAIJZYBQAgllgFACDWP464PTL4ODg1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting style\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"font.family\"] = \"sans-serif\"\n",
    "rcParams[\"font.sans-serif\"] = [\"Computer Modern Sans\"]\n",
    "sns.set_style('white')\n",
    "sns.set_palette(\"colorblind\", 12) #Paired\n",
    "sns.palplot(sns.color_palette())\n",
    "rcParams['xtick.major.size'] = 2\n",
    "rcParams['xtick.major.width'] = 1\n",
    "rcParams['ytick.major.size'] = 2\n",
    "rcParams['ytick.major.width'] = 1\n",
    "rcParams['xtick.direction'] = 'in'\n",
    "rcParams['ytick.direction'] = 'in'\n",
    "colTF = sns.color_palette()[2] \n",
    "colGP = sns.color_palette()[0]\n",
    "colGP2 = sns.color_palette()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "configfilename=\"tmpsim/parametersTest.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Objects 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-9f5e795f15c5>:12: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  numObjectsTraining = np.sum(1 for line in open(params['training_catFile']))\n"
     ]
    }
   ],
   "source": [
    "# Read parameter files and data (file names need to be updated)\n",
    "# Load SEDS, bands, grids, etc.\n",
    "params = parseParamFile(configfilename, verbose=False)\n",
    "#params['training_catFile'] = '/Users/bl/Dropbox/repos/Delight/data/galaxies-fluxredshifts_small.txt'\n",
    "#params['target_catFile'] = '/Users/bl/Dropbox/repos/Delight/data/galaxies-fluxredshifts_small2.txt'\n",
    "bandCoefAmplitudes, bandCoefPositions, bandCoefWidths, norms\\\n",
    "    = readBandCoefficients(params)\n",
    "bandNames = params['bandNames']\n",
    "numBands, numCoefs = bandCoefAmplitudes.shape\n",
    "redshiftDistGrid, redshiftGrid, redshiftGridGP = createGrids(params)\n",
    "f_mod = readSEDs(params)\n",
    "numObjectsTraining = np.sum(1 for line in open(params['training_catFile']))\n",
    "print('Number of Training Objects', numObjectsTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filter coefficients (Gaussian mixture model approximation)\n",
    "# Then compute mean and size of filters, for plotting later.\n",
    "bandwavelengths = np.zeros((numBands, 2))\n",
    "for i in range(numBands):\n",
    "    amps, mus, sigs = bandCoefAmplitudes[i, :], bandCoefPositions[i, :], bandCoefWidths[i, :]\n",
    "    lamMin, lamMax = np.min(mus - 2*sigs), np.max(mus + 2*sigs) \n",
    "    x = np.linspace(lamMin, lamMax, 5000)\n",
    "    y = np.sum(np.exp(-0.5*((mus[None, :]-x[:, None])/sigs[None, :])**2), axis=1)\n",
    "    bandwavelengths[i, 0] = np.average(x, weights=y)\n",
    "    bandwavelengths[i, 1] = np.sqrt(np.average((x-bandwavelengths[i, 0])**2, weights=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.errorbar(bandwavelengths[:, 0], fluxes, yerr=fluxesVar**0.5, xerr=bandwavelengths[:, 1], fmt='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load templates\n",
    "dir_seds = params['templates_directory']\n",
    "dir_filters = params['bands_directory']\n",
    "lambdaRef = params['lambdaRef']\n",
    "sed_names = params['templates_names']\n",
    "fmt = '.dat'\n",
    "sed_interps = np.zeros((len(sed_names), ), dtype=object)\n",
    "for i, sed_name in enumerate(sed_names):\n",
    "    seddata = np.genfromtxt(dir_seds + '/' + sed_name + fmt)\n",
    "    seddata[:, 1] *= seddata[:, 0]**2. / 3e18\n",
    "    ref = np.interp(lambdaRef, seddata[:, 0], seddata[:, 1])\n",
    "    seddata[:, 1] /= ref\n",
    "    sed_interps[i] = interp1d(seddata[:, 0], seddata[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GP \n",
    "# Could change hyperparameters here\n",
    "DL = approx_DL()\n",
    "gp = PhotozGP(f_mod, bandCoefAmplitudes, bandCoefPositions, bandCoefWidths,\n",
    "              params['lines_pos'], params['lines_width'],\n",
    "              params['V_C'], params['V_L'],\n",
    "              params['alpha_C'], params['alpha_L'],\n",
    "              redshiftGridGP, use_interpolators=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a function to construct the GP residuals in wavelength space, with the two RBF kernels\n",
    "# (In delight this is done in redshift/band space, but we want the actual SED here)\n",
    "\n",
    "lamMin = 3.7e3#np.min(bandwavelengths[:, 0]-2*bandwavelengths[:, 1])\n",
    "lamMax = 1.1e4#np.max(bandwavelengths[:, 0]+2*bandwavelengths[:, 1])\n",
    "#wavs = np.logspace(np.log10(lamMin), np.log10(lamMax), 80) \n",
    "wavs=np.linspace(lamMin, lamMax, 10)\n",
    "#wavs_hi = np.logspace(np.log10(lamMin), np.log10(lamMax), 2000) \n",
    "#wavs_hi=np.linspace(lamMin, lamMax, 1000)\n",
    "wavs_hi=np.linspace(lamMin, lamMax, 20)\n",
    "\n",
    "\n",
    "\n",
    "def drawSEDresiduals(gp, z, ell, wavs):\n",
    "    opz = 1 + z\n",
    "    dWav = wavs[:, None] - wavs[None, :]\n",
    "    \n",
    "    cov_C = gp.kernel.var_C *\\\n",
    "        np.exp(-0.5*(dWav/opz/gp.kernel.alpha_C)**2)\n",
    "    \n",
    "    cov_L = 0*cov_C\n",
    "    \n",
    "    for mu, sig in zip(gp.kernel.lines_mu, gp.kernel.lines_sig):\n",
    "        cov_L += gp.kernel.var_L *\\\n",
    "            np.exp(-0.5*(dWav/opz/gp.kernel.alpha_L)**2) *\\\n",
    "            np.exp(-0.5*((wavs[:, None]/opz-mu)/sig)**2) *\\\n",
    "            np.exp(-0.5*((wavs[None, :]/opz-mu)/sig)**2)\n",
    "        \n",
    "    fac = opz * ell / 4 / np.pi / gp.kernel.DL_z(z)**2\n",
    "    \n",
    "    residuals = fac * np.random.multivariate_normal(0*wavs, cov_C + cov_L)\n",
    "    \n",
    "    numB = gp.kernel.fcoefs_amp.shape[0]\n",
    "    \n",
    "    filters = np.zeros((numB, wavs.size))\n",
    "    \n",
    "    for i in range(numB):\n",
    "        for amp, mu, sig in zip(gp.kernel.fcoefs_amp[i, :],\n",
    "                                gp.kernel.fcoefs_mu[i, :],\n",
    "                                gp.kernel.fcoefs_sig[i, :]):\n",
    "            filters[i, :] += amp * np.exp(-0.5*((wavs-mu)/sig)**2)\n",
    "            \n",
    "    return residuals, fac, cov_C + cov_L, filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) model =  [[[4.21999085e-08 5.65767585e-08 1.23301184e-07 2.97698526e-07\n",
      "   1.05781239e-06 2.32892545e-06]\n",
      "  [2.77435129e-07 6.24249071e-07 1.10463842e-06 1.47053721e-06\n",
      "   1.91781846e-06 2.95743479e-06]\n",
      "  [9.82758814e-07 1.76293320e-06 2.54470040e-06 2.88018271e-06\n",
      "   3.57844603e-06 4.56703023e-06]\n",
      "  [2.71600787e-06 3.33241471e-06 3.89554336e-06 4.56640314e-06\n",
      "   5.17148307e-06 5.59646151e-06]\n",
      "  [5.16682398e-06 6.28473220e-06 6.28857389e-06 6.95143891e-06\n",
      "   7.00097130e-06 8.11733760e-06]\n",
      "  [2.56611652e-06 3.64053645e-06 4.54402053e-06 4.79651195e-06\n",
      "   5.11580304e-06 5.88009517e-06]\n",
      "  [1.23849300e-05 1.24500223e-05 1.18387014e-05 1.10676011e-05\n",
      "   1.05990957e-05 9.91453160e-06]\n",
      "  [2.78842161e-05 2.52208876e-05 2.24543177e-05 1.93935983e-05\n",
      "   1.71149438e-05 1.55283813e-05]]]\n",
      "1) fluxes =  [2.72111406 3.52621314 3.79059658 4.72490472 4.98551306 5.54940699]\n",
      "z =  1.9722299138465411\n",
      "ellMLs.shape =  (1, 8) ellMLs =  [[3358859.91371741 2770959.10287451 1549035.75803175 1003906.17209946\n",
      "   610570.00799228  952863.29043561  309776.44199472  147205.21048212]]\n",
      "bestType =  3\n",
      "X.shape =  (6, 3)  X = [[0.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [1.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [2.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [3.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [4.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [5.00000000e+00 1.97222991e+00 1.00390617e+06]]\n",
      "2) model_mean =  [[1.23745522e+05 2.31629384e+05 3.33532909e+05 3.60489683e+05\n",
      "  4.54280348e+05 5.29293554e+05]\n",
      " [2.98535645e+04 5.71315784e+04 8.22740931e+04 8.92492319e+04\n",
      "  1.11255022e+05 1.31091996e+05]\n",
      " [1.24965749e+04 2.43599669e+04 3.50404970e+04 3.85924115e+04\n",
      "  4.71488936e+04 5.62123484e+04]\n",
      " ...\n",
      " [7.69084762e-01 1.59255465e+00 1.99572816e+00 2.43245660e+00\n",
      "  2.50254569e+00 2.82691038e+00]\n",
      " [7.50529333e-01 1.58363205e+00 1.98027602e+00 2.42332589e+00\n",
      "  2.48472592e+00 2.81306908e+00]\n",
      " [7.32033629e-01 1.57470166e+00 1.96566565e+00 2.41342471e+00\n",
      "  2.46743187e+00 2.79826079e+00]]\n",
      "2) fluxes =  [2.72111406 3.52621314 3.79059658 4.72490472 4.98551306 5.54940699]\n",
      "nwalker= 0  p0[i]= [2.57195034 3.17665776 3.90615565 3.65083547 5.28559252 5.108232\n",
      " 5.09445681 6.58866217 5.10035389 6.17872827]  :::  -19.478836803700396\n",
      "nwalker= 1  p0[i]= [2.57305714 3.17779296 3.90722831 3.65177677 5.28636356 5.1088198\n",
      " 5.09486952 6.58892552 5.10050347 6.17866596]  :::  -19.49603908923597\n",
      "nwalker= 2  p0[i]= [2.57252368 3.17721309 3.90667483 3.65128004 5.28591996 5.10841185\n",
      " 5.09448414 6.58856324 5.1001786  6.17841883]  :::  -19.47683986525835\n",
      "nwalker= 3  p0[i]= [2.57185039 3.17651956 3.90597413 3.6506091  5.28533042 5.10796011\n",
      " 5.09422193 6.58852605 5.10037232 6.17886033]  :::  -19.46472790106375\n",
      "nwalker= 4  p0[i]= [2.57259855 3.17742039 3.90695728 3.65158412 5.28620368 5.10865216\n",
      " 5.09468152 6.58873788 5.10035448 6.17881198]  :::  -19.49267225767607\n",
      "nwalker= 5  p0[i]= [2.57233774 3.17703688 3.90648252 3.65101673 5.28552192 5.10783874\n",
      " 5.09374805 6.58773967 5.09939044 6.17786853]  :::  -19.435408964984212\n",
      "nwalker= 6  p0[i]= [2.57194702 3.1767272  3.90628064 3.6509372  5.28556469 5.1079899\n",
      " 5.09398225 6.58802336 5.09968573 6.17825576]  :::  -19.45569120313167\n",
      "nwalker= 7  p0[i]= [2.57245749 3.17706217 3.90637897 3.65082113 5.28532437 5.10774015\n",
      " 5.09381262 6.5879615  5.09968771 6.17809327]  :::  -19.431355245089648\n",
      "nwalker= 8  p0[i]= [2.57195757 3.17649324 3.90586081 3.65045247 5.28515961 5.10778244\n",
      " 5.09401893 6.58825651 5.09998581 6.17840085]  :::  -19.446636750558188\n",
      "nwalker= 9  p0[i]= [2.57223541 3.17697728 3.90645294 3.65102598 5.28558062 5.10793929\n",
      " 5.09385601 6.58779756 5.09932983 6.17753373]  :::  -19.442282221638695\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Initial state has a large condition number. Make sure that your walkers are linearly independent for the best performance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ea24139593e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob,\n\u001b[1;32m    110\u001b[0m                                                 args=[sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms])\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36mrun_mcmc\u001b[0;34m(self, initial_state, nsteps, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mwalkers_independent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         ):\n\u001b[0;32m--> 253\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;34m\"Initial state has a large condition number. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;34m\"Make sure that your walkers are linearly independent for the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Initial state has a large condition number. Make sure that your walkers are linearly independent for the best performance"
     ]
    }
   ],
   "source": [
    "numZ = redshiftGrid.size\n",
    "all_z = np.zeros((numObjectsTraining, ))\n",
    "all_fluxes = np.zeros((numObjectsTraining, numBands))\n",
    "all_fluxes_var = np.zeros((numObjectsTraining, numBands))\n",
    "all_bestTypes = np.zeros((numObjectsTraining, ), dtype=int)\n",
    "all_model_mean = np.zeros((numZ, numObjectsTraining, numBands))\n",
    "all_model_covar = np.zeros((numZ, numObjectsTraining, numBands))\n",
    "\n",
    "loc = - 1\n",
    "trainingDataIter1 = getDataFromFile(params, 0, numObjectsTraining,prefix=\"training_\", getXY=True,CV=True)\n",
    "\n",
    "# loop on training data\n",
    "\n",
    "for z, normedRefFlux,\\\n",
    "    bands, fluxes, fluxesVar,\\\n",
    "    bandsCV, fluxesCV, fluxesVarCV,\\\n",
    "        X, Y, Yvar in trainingDataIter1:\n",
    "    loc += 1\n",
    "\n",
    "    themod = np.zeros((1, f_mod.shape[0], bands.size))\n",
    "    \n",
    "    # loop on templates\n",
    "    for it in range(f_mod.shape[0]):\n",
    "        for ib, band in enumerate(bands):\n",
    "            themod[0, it, ib] = f_mod[it, band](z)\n",
    "            \n",
    "    # compute  the likelihood        \n",
    "    chi2_grid, ellMLs = scalefree_flux_likelihood(fluxes, fluxesVar, themod, returnChi2=True)\n",
    "    \n",
    "    \n",
    "    print(\"1) model = \", themod)\n",
    "    print(\"1) fluxes = \",fluxes)\n",
    "    \n",
    "    \n",
    "    print(\"z = \",z)\n",
    "    \n",
    "    print(\"ellMLs.shape = \",ellMLs.shape, \"ellMLs = \",ellMLs)\n",
    "    \n",
    "    bestType = np.argmin(chi2_grid)\n",
    "    \n",
    "    print(\"bestType = \",bestType)\n",
    "    \n",
    "    ell = ellMLs[0, bestType]\n",
    "    #ell2 = normedRefFlux * 4 * np.pi * (DL(z)**2. * (1+z)) / params['fluxLuminosityNorm']\n",
    "    \n",
    "    # fit the gaussian process\n",
    "    X[:, 2] = ell\n",
    "    \n",
    "    print(\"X.shape = \",X.shape, \" X =\", X)\n",
    "    \n",
    "    gp.setData(X, Y, Yvar, bestType)\n",
    "    model_mean, model_covar = gp.predictAndInterpolate(redshiftGrid, ell=ell)\n",
    "    all_model_mean[:, loc, :], all_model_covar[:, loc, :] = model_mean, model_covar\n",
    "\n",
    "    print(\"2) model_mean = \",model_mean)\n",
    "    print(\"2) fluxes = \",fluxes)\n",
    "    \n",
    "    \n",
    "    all_z[loc] = z\n",
    "    all_bestTypes[loc] = bestType\n",
    "    all_fluxes[loc, bands] = fluxes\n",
    "    all_fluxes_var[loc, bands] = fluxesVar\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if loc < 10:\n",
    "        if True:\n",
    "            fac = ell * (1+z)**2. / DL(z)**2. / (4*np.pi) * 1e4/2.3\n",
    "            sedtf = sed_interps[bestType](wavs/(1+z)) * fac\n",
    "            sedtf_hi = sed_interps[bestType](wavs_hi/(1+z)) * fac\n",
    "\n",
    "            if True:\n",
    "                residuals, fac, cov, filters = drawSEDresiduals(gp, z, ell, wavs)\n",
    "                residuals_hi, fac_hi, cov_hi, filters_hi = drawSEDresiduals(gp, z, ell, wavs_hi)\n",
    "                filternorms = [np.trapz(filters_hi[ib], x=wavs_hi) for i, ib in enumerate(bands)]\n",
    "                sed = np.random.uniform(wavs.size) * wavs\n",
    "                #icov = np.linalg.inv(cov)\n",
    "                det = np.linalg.det(cov)\n",
    "                \n",
    "                def lnprob(sed, sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms):\n",
    "                    sedfluxes = np.zeros((bands.size, ))\n",
    "                    sed_hi = interp1d(wavs, sed, kind='cubic')(wavs_hi)#np.interp(wavs_hi, wavs, sed)\n",
    "                    for i, ib in enumerate(bands):\n",
    "                        sedfluxes[i] = np.trapz(filters_hi[ib]*sed_hi, x=wavs_hi) / filternorms[i]\n",
    "                    lp = np.sum(-0.5*(sedfluxes - fluxes)**2/fluxesVar) #- 0.5 * np.prod(np.log(fluxesVar))\n",
    "                    res = (sed - sedtf) / fac\n",
    "                    #print(lp,  np.sum(-0.5*np.dot(res, np.linalg.solve(cov, res))), end=\" \")\n",
    "                    #lp += np.sum(-0.5*np.dot(res, np.linalg.solve(cov, res))) \n",
    "                    return lp\n",
    "                ndim = wavs.size\n",
    "                #nwalkers = ndim * 10\n",
    "                nwalkers =  10\n",
    "                \n",
    "                #ndim, nwalkers = 5, 100\n",
    "                #ivar = 1. / np.random.rand(ndim)\n",
    "                #p0 = np.random.randn(nwalkers, ndim)\n",
    "                #sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[ivar])\n",
    "                #sampler.run_mcmc(p0, 10000)\n",
    "                \n",
    "                ymax = fluxes.max() * 1.2\n",
    "                ymin = fluxes.min() / 2\n",
    "                p0 = np.random.uniform(low=ymin, high=ymax, size=ndim * nwalkers).reshape((nwalkers, ndim))\n",
    "                for i in range(nwalkers):\n",
    "                    p0[i] = 1*sedtf + fac * np.random.multivariate_normal(0*wavs, cov)\n",
    "                    print(\"nwalker=\",i,\" p0[i]=\",p0[i],\" ::: \",lnprob(p0[i], sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms))\n",
    "                #stop\n",
    "                sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob,\n",
    "                                                args=[sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms])\n",
    "                pos, prob, state = sampler.run_mcmc(p0, 20,progress=True)\n",
    "                sampler.reset()\n",
    "                sampler.run_mcmc(pos, 20,progress=True)\n",
    "                print(\"Mean acceptance fraction: {0:.3f}\"\n",
    "                        .format(np.mean(sampler.acceptance_fraction)))\n",
    "                seds = sampler.flatchain\n",
    "                sedmean, sedstd = seds.mean(axis=0), seds.std(axis=0)\n",
    "                sedmean_hi = interp1d(wavs, sedmean, kind='cubic')(wavs_hi)\n",
    "                sedstd_hi = interp1d(wavs, sedstd, kind='cubic')(wavs_hi)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "            #ax.plot(wavs, sedtf, 'k')\n",
    "            ax.plot(wavs_hi, sedtf_hi, c=colTF, label='Standard template fitting') \n",
    "            ax.plot(wavs_hi, sedmean_hi, color=colGP, label='New method')\n",
    "            ax.fill_between(wavs_hi, sedmean_hi+sedstd_hi, sedmean_hi-sedstd_hi, color=colGP, alpha=0.4)\n",
    "            \n",
    "            \n",
    "            #ax.fill_between(wavs, sedmean+sedstd, sedmean-sedstd, color='b', alpha=0.2)\n",
    "            #for w in wavs:\n",
    "            #    ax.axvline(w, c='gray', alpha=0.5, lw=0.5)\n",
    "            #for i in range(seds.shape[0]):\n",
    "            #    ax.plot(wavs_hi, interp1d(wavs, seds[i, :], kind='cubic')(wavs_hi), c='gray', alpha=0.2, lw=0.3)\n",
    "            ax.errorbar(bandwavelengths[bands, 0], fluxes, \n",
    "                        xerr=bandwavelengths[bands, 1], yerr=np.sqrt(fluxesVar),\n",
    "                       fmt='o', c='k', markersize=5, label='Deep training photometry')\n",
    "            ax.errorbar(bandwavelengths[bandsCV, 0], fluxesCV, \n",
    "                        xerr=bandwavelengths[bandsCV, 1], yerr=np.sqrt(fluxesVarCV),\n",
    "                       fmt='s', c='b', markersize=5, label='Shallow testing photometry')\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_ylabel(r'$L_\\nu(\\lambda)$')\n",
    "            #ax.set_yticks(np.linspace(10**-5, 10**-4, 10))\n",
    "            ax.set_xlabel(r'$\\lambda$ [$\\AA$]')\n",
    "            ax.set_xlim([lamMin, lamMax])\n",
    "            ax.set_xticks(np.linspace(4e3, 1e4, 7))\n",
    "            ax.set_xticklabels(np.linspace(4e3, 1e4, 7))\n",
    "            ax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "            #ax.set_ylim([0.5*np.min(sedtf), 2.5*np.max(sedtf)])\n",
    "            ax.legend(ncol=2, frameon=False, loc='upper left')\n",
    "            fig.tight_layout()\n",
    "            fig.savefig('./figures/showcase/traininggalaxy_fnulambda-'+str(loc)+'.pdf')\n",
    "            \n",
    "        if False:\n",
    "            fig, axs = plt.subplots(4, numBands//4, figsize=(12, 6), sharex=True, sharey=True)\n",
    "            for i in range(numBands//4):\n",
    "                axs[-1, i].set_xlabel('Redshift')\n",
    "            for i in range(4):\n",
    "                axs[i, 0].set_ylabel('Flux')\n",
    "            axs = axs.ravel()\n",
    "            temp = np.concatenate([ell*f_mod[bestType, i](redshiftGrid)*redshiftGrid**2\n",
    "                                   for i, bnm in enumerate(bandNames)])\n",
    "            axs[-1].set_ylim([0.5*np.min(temp), 2*np.max(temp)])\n",
    "            for i, bnm in enumerate(bandNames):\n",
    "                axs[i].text(0.1, 0.8*np.max(temp), bnm.replace('_', ' '))\n",
    "                axs[i].plot(redshiftGrid, ell*f_mod[bestType, i](redshiftGrid)*redshiftGrid**2,\n",
    "                            c=colTF, label='Standard template fitting', ls='dashed', zorder=2)\n",
    "                axs[i].plot(redshiftGrid, model_mean[:, i]*redshiftGrid**2,\n",
    "                            c=colGP, label='New method', zorder=1)#, label=bnm.replace('_', ' '))\n",
    "                axs[i].fill_between(redshiftGrid, \n",
    "                                    (model_mean[:, i]-np.sqrt(model_covar[:, i]))*redshiftGrid**2, \n",
    "                                    (model_mean[:, i]+np.sqrt(model_covar[:, i]))*redshiftGrid**2,\n",
    "                                    color=colGP, alpha=0.4, zorder=0)\n",
    "                if i in bands:\n",
    "                    pos = list(bands).index(i)\n",
    "                    axs[i].errorbar(z, fluxes[pos]*z**2, yerr=np.sqrt(fluxesVar[pos])*z**2, c='k', markersize=5, fmt='o')\n",
    "                if i in bandsCV:\n",
    "                    pos = list(bandsCV).index(i)\n",
    "                    axs[i].errorbar(z, fluxesCV[pos]*z**2, yerr=np.sqrt(fluxesVarCV[pos])*z**2, c='b', markersize=5, fmt='s')\n",
    "                #axs[i].set_ylim([np.min(model_mean), np.max(model_mean)])\n",
    "                axs[i].set_xticks([0, 0.5, 1.0])\n",
    "            axs[0].legend(ncol=3, frameon=False, loc='upper left', bbox_to_anchor=(0.0, 1.4))\n",
    "            axs[-1].set_yscale('log')\n",
    "            axs[-1].set_xlim([0, 1.5])\n",
    "            fig.subplots_adjust(wspace=0, hspace=0)\n",
    "            fig.savefig('./figures/showcase/traininggalaxy_fluxredshiftmodel-'+str(loc)+'.pdf')\n",
    "            \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the redshift / photometric model\n",
    "dir_seds = params['templates_directory']\n",
    "dir_filters = params['bands_directory']\n",
    "lambdaRef = params['lambdaRef']\n",
    "sed_names = params['templates_names']\n",
    "f_mod_grid = np.zeros((redshiftGrid.size, len(sed_names),\n",
    "                  len(params['bandNames'])))\n",
    "for t, sed_name in enumerate(sed_names):\n",
    "    f_mod_grid[:, t, :] = np.loadtxt(dir_seds + '/' + sed_name +\n",
    "                                '_fluxredshiftmod.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run that to look at redshift PDFs\n",
    "p_t = params['p_t'][all_bestTypes][None, :]\n",
    "p_z_t = params['p_z_t'][all_bestTypes][None, :]\n",
    "prior = np.exp(-0.5*((redshiftGrid[:, None]-all_z[None, :])/params['zPriorSigma'])**2)\n",
    "Ncompress = params['Ncompress']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 2.5), sharey=True)\n",
    "\n",
    "loc = -1\n",
    "targetDataIter = getDataFromFile(params, 0, numObjectsTraining,\n",
    "                                 prefix=\"target_\", getXY=False)\n",
    "for z, normedRefFlux, bands, fluxes, fluxesVar, bCV, fCV, fvCV in targetDataIter:\n",
    "    loc += 1\n",
    "    if loc < 100:\n",
    "        fulllike_grid = np.zeros((all_model_mean.shape[0], all_model_mean.shape[1]))\n",
    "        ell_hat_z = normedRefFlux * 4 * np.pi\\\n",
    "            * params['fluxLuminosityNorm'] \\\n",
    "            * (DL(redshiftGrid)**2. * (1+redshiftGrid))\n",
    "        ell_hat_z[:] = 1.0\n",
    "        params['ellPriorSigma'] = 0.2\n",
    "        approx_flux_likelihood_cy(fulllike_grid,\n",
    "            all_model_mean.shape[0], all_model_mean.shape[1], bands.size,\n",
    "            fluxes, fluxesVar, all_model_mean[:, :, bands],\n",
    "            all_model_covar[:, :, bands], \n",
    "            ell_hat_z, (ell_hat_z*params['ellPriorSigma'])**2\n",
    "        )\n",
    "        fulllike_grid *= prior\n",
    "        evidences = np.trapz(fulllike_grid, x=redshiftGrid, axis=0)\n",
    "        sortind = np.argsort(evidences)[::-1][0:Ncompress]\n",
    "        like_grid = fulllike_grid.sum(axis=1)\n",
    "        like_grid_comp = fulllike_grid[:, sortind].sum(axis=1)\n",
    "        alllike_grid_cww = np.zeros((f_mod_grid.shape[0], f_mod_grid.shape[1]))\n",
    "        params['ellPriorSigma'] = 1e12\n",
    "        approx_flux_likelihood_cy(alllike_grid_cww,\n",
    "            f_mod_grid.shape[0], f_mod_grid.shape[1], bands.size,\n",
    "            fluxes, fluxesVar, f_mod_grid[:, :, bands], 0*f_mod_grid[:, :, bands], \n",
    "            ell_hat_z, (ell_hat_z*params['ellPriorSigma'])**2\n",
    "        )\n",
    "        b_in = np.array(params['p_t'])[None, :]\n",
    "        beta2 = np.array(params['p_z_t'])**2.0\n",
    "        p_z = b_in * redshiftGrid[:, None] * np.exp(-0.5 * redshiftGrid[:, None]**2 / beta2[None, :]) / beta2[None, :]\n",
    "        alllike_grid_cww *= p_z\n",
    "        besttype = np.argmax(alllike_grid_cww.sum(axis=0))\n",
    "        like_grid_cww = alllike_grid_cww.sum(axis=1)  # [:, besttype]\n",
    "        if like_grid.sum() > 0:\n",
    "            zphotmean = np.average(redshiftGrid, weights=like_grid)\n",
    "            if zphotmean > 0.0 and zphotmean < 2.5 and z < 2.8:\n",
    "\n",
    "                for ax in axs:\n",
    "                    ax.cla()\n",
    "                for ii in sortind:\n",
    "                    axs[1].plot(redshiftGrid, fulllike_grid[:, ii], c='gray', lw=1, alpha=0.6)\n",
    "                axs[0].plot(redshiftGrid, like_grid, c=colGP, lw=2, label='New method')\n",
    "                like_grid_cww = like_grid_cww * np.max(like_grid) / np.max(like_grid_cww)\n",
    "                axs[0].plot(redshiftGrid, like_grid_cww, c=colTF, lw=2, label='Standard template fitting')\n",
    "                axs[1].plot(redshiftGrid, like_grid_comp, c=colGP, lw=2, label='Compressed new method')\n",
    "                axs[0].axvline(z, c='k', lw=1, ls='dashed', label='True redshift')\n",
    "                axs[1].axvline(z, c='k', lw=1, ls='dashed')\n",
    "                axs[0].set_ylabel(r'$p(z | \\hat{\\mathbf{F}})$')\n",
    "                axs[1].set_xlabel('Redshift')\n",
    "                thegr = np.concatenate((redshiftGrid[np.logical_and(like_grid_cww > 0.01, like_grid > 0.01)],\n",
    "                                 all_z[sortind]))    \n",
    "                axs[1].set_xlim([np.min(thegr), np.max(thegr)])\n",
    "                axs[0].set_xlim([np.min(thegr), np.max(thegr)])\n",
    "                axs[0].set_xlabel('Redshift')\n",
    "                ylimax = 1.2*np.max(np.concatenate((like_grid, like_grid_cww)))\n",
    "                axs[0].set_ylim([0, ylimax])\n",
    "                for iioff, ii in enumerate(sortind):\n",
    "                    if iioff == 0:\n",
    "                        lb = 'Training galaxies'\n",
    "                    else:\n",
    "                        lb = None\n",
    "                    axs[1].scatter(all_z[ii], ylimax*0.99, c='gray', marker='x', lw=2, s=10, label=lb)\n",
    "                axs[0].yaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "                axs[0].legend(loc='upper right', frameon=False, ncol=2, bbox_to_anchor=(1.0, 1.35))\n",
    "                axs[0].set_yticks([])\n",
    "                axs[1].legend(loc='upper right', frameon=False, ncol=1, bbox_to_anchor=(0.8, 1.35))\n",
    "                axs[1].set_yticks([])\n",
    "                #fig.tight_layout()\n",
    "                fig.subplots_adjust(wspace=0, hspace=0, bottom=0.2, top=0.8, left=0.05, right=0.95)\n",
    "                fig.savefig('./figures/showcases/data-pdfs-'+str(loc)+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
