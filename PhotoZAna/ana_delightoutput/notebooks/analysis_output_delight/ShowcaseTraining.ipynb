{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show caseon training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "sys.path.append('../')\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import emcee\n",
    "from delight.io import *\n",
    "from delight.utils import *\n",
    "from delight.utils_cy import approx_flux_likelihood_cy\n",
    "from delight.photoz_gp import PhotozGP\n",
    "from delight.photoz_kernels import Photoz_mean_function, Photoz_kernel\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAABECAYAAACmlnyPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAACZ0lEQVR4nO3aIW5UURiG4VtKK8Y0GQGBITUUDCCKGccOUCC6BlSTLgHNAkgIKBQGh6TBXV2NIGQEKQSShlS06WUB0447838Znkf+x3zyFWdtGIahAwCAQNeqBwAAwFXEKgAAscQqAACxxCoAALHEKgAAsa4verz7cLc7H42XtWXpHm1+rZ7Q1NH6jeoJzTw4+VE9oamLjfvVE9ra+FW9oKnR5qR6QlPHZ3+qJzQ13vpZPaGZb6f3qic09fvkb/WEpla9W47PbnZ938/dF8bq+WjcfX+y32pTucM7z6onNLWz9bx6QjOfDl9VT2jq9Pbb6glNXdx6Xz2hqd3tl9UTmno9+1g9oam9p++qJzTz4uhN9YSmPnyeD51VsurdcvDl8aV33wAAAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiCVWAQCIJVYBAIglVgEAiLU2DMNw1eN0Ou0mk8ky9wAA8B+azWZd3/dz94WxCgAAlXwDAAAgllgFACCWWAUAIJZYBQAgllgFACDWP464PTL4ODg1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting style\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"font.family\"] = \"sans-serif\"\n",
    "rcParams[\"font.sans-serif\"] = [\"Computer Modern Sans\"]\n",
    "sns.set_style('white')\n",
    "sns.set_palette(\"colorblind\", 12) #Paired\n",
    "sns.palplot(sns.color_palette())\n",
    "rcParams['xtick.major.size'] = 2\n",
    "rcParams['xtick.major.width'] = 1\n",
    "rcParams['ytick.major.size'] = 2\n",
    "rcParams['ytick.major.width'] = 1\n",
    "rcParams['xtick.direction'] = 'in'\n",
    "rcParams['ytick.direction'] = 'in'\n",
    "colTF = sns.color_palette()[2] \n",
    "colGP = sns.color_palette()[0]\n",
    "colGP2 = sns.color_palette()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configfilename=\"tmpsim/parametersTest.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Objects 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9676/159012008.py:12: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  numObjectsTraining = np.sum(1 for line in open(params['training_catFile']))\n"
     ]
    }
   ],
   "source": [
    "# Read parameter files and data (file names need to be updated)\n",
    "# Load SEDS, bands, grids, etc.\n",
    "params = parseParamFile(configfilename, verbose=False)\n",
    "#params['training_catFile'] = '/Users/bl/Dropbox/repos/Delight/data/galaxies-fluxredshifts_small.txt'\n",
    "#params['target_catFile'] = '/Users/bl/Dropbox/repos/Delight/data/galaxies-fluxredshifts_small2.txt'\n",
    "bandCoefAmplitudes, bandCoefPositions, bandCoefWidths, norms\\\n",
    "    = readBandCoefficients(params)\n",
    "bandNames = params['bandNames']\n",
    "numBands, numCoefs = bandCoefAmplitudes.shape\n",
    "redshiftDistGrid, redshiftGrid, redshiftGridGP = createGrids(params)\n",
    "f_mod = readSEDs(params)\n",
    "numObjectsTraining = np.sum(1 for line in open(params['training_catFile']))\n",
    "print('Number of Training Objects', numObjectsTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filter coefficients (Gaussian mixture model approximation)\n",
    "# Then compute mean and size of filters, for plotting later.\n",
    "bandwavelengths = np.zeros((numBands, 2))\n",
    "for i in range(numBands):\n",
    "    amps, mus, sigs = bandCoefAmplitudes[i, :], bandCoefPositions[i, :], bandCoefWidths[i, :]\n",
    "    lamMin, lamMax = np.min(mus - 2*sigs), np.max(mus + 2*sigs) \n",
    "    x = np.linspace(lamMin, lamMax, 5000)\n",
    "    y = np.sum(np.exp(-0.5*((mus[None, :]-x[:, None])/sigs[None, :])**2), axis=1)\n",
    "    bandwavelengths[i, 0] = np.average(x, weights=y)\n",
    "    bandwavelengths[i, 1] = np.sqrt(np.average((x-bandwavelengths[i, 0])**2, weights=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.errorbar(bandwavelengths[:, 0], fluxes, yerr=fluxesVar**0.5, xerr=bandwavelengths[:, 1], fmt='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load templates\n",
    "dir_seds = params['templates_directory']\n",
    "dir_filters = params['bands_directory']\n",
    "lambdaRef = params['lambdaRef']\n",
    "sed_names = params['templates_names']\n",
    "#fmt = '.dat'\n",
    "fmt = '.sed'\n",
    "sed_interps = np.zeros((len(sed_names), ), dtype=object)\n",
    "for i, sed_name in enumerate(sed_names):\n",
    "    seddata = np.genfromtxt(dir_seds + '/' + sed_name + fmt)\n",
    "    seddata[:, 1] *= seddata[:, 0]**2. / 3e18\n",
    "    ref = np.interp(lambdaRef, seddata[:, 0], seddata[:, 1])\n",
    "    seddata[:, 1] /= ref\n",
    "    sed_interps[i] = interp1d(seddata[:, 0], seddata[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GP \n",
    "# Could change hyperparameters here\n",
    "DL = approx_DL()\n",
    "gp = PhotozGP(f_mod, bandCoefAmplitudes, bandCoefPositions, bandCoefWidths,\n",
    "              params['lines_pos'], params['lines_width'],\n",
    "              params['V_C'], params['V_L'],\n",
    "              params['alpha_C'], params['alpha_L'],\n",
    "              redshiftGridGP, use_interpolators=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a function to construct the GP residuals in wavelength space, with the two RBF kernels\n",
    "# (In delight this is done in redshift/band space, but we want the actual SED here)\n",
    "\n",
    "lamMin = 3.7e3#np.min(bandwavelengths[:, 0]-2*bandwavelengths[:, 1])\n",
    "lamMax = 1.1e4#np.max(bandwavelengths[:, 0]+2*bandwavelengths[:, 1])\n",
    "#wavs = np.logspace(np.log10(lamMin), np.log10(lamMax), 80) \n",
    "wavs=np.linspace(lamMin, lamMax, 10)\n",
    "#wavs_hi = np.logspace(np.log10(lamMin), np.log10(lamMax), 2000) \n",
    "#wavs_hi=np.linspace(lamMin, lamMax, 1000)\n",
    "wavs_hi=np.linspace(lamMin, lamMax, 20)\n",
    "\n",
    "\n",
    "\n",
    "def drawSEDresiduals(gp, z, ell, wavs):\n",
    "    opz = 1 + z\n",
    "    dWav = wavs[:, None] - wavs[None, :]\n",
    "    \n",
    "    cov_C = gp.kernel.var_C *\\\n",
    "        np.exp(-0.5*(dWav/opz/gp.kernel.alpha_C)**2)\n",
    "    \n",
    "    cov_L = 0*cov_C\n",
    "    \n",
    "    for mu, sig in zip(gp.kernel.lines_mu, gp.kernel.lines_sig):\n",
    "        cov_L += gp.kernel.var_L *\\\n",
    "            np.exp(-0.5*(dWav/opz/gp.kernel.alpha_L)**2) *\\\n",
    "            np.exp(-0.5*((wavs[:, None]/opz-mu)/sig)**2) *\\\n",
    "            np.exp(-0.5*((wavs[None, :]/opz-mu)/sig)**2)\n",
    "        \n",
    "    fac = opz * ell / 4 / np.pi / gp.kernel.DL_z(z)**2\n",
    "    \n",
    "    residuals = fac * np.random.multivariate_normal(0*wavs, cov_C + cov_L)\n",
    "    \n",
    "    numB = gp.kernel.fcoefs_amp.shape[0]\n",
    "    \n",
    "    filters = np.zeros((numB, wavs.size))\n",
    "    \n",
    "    for i in range(numB):\n",
    "        for amp, mu, sig in zip(gp.kernel.fcoefs_amp[i, :],\n",
    "                                gp.kernel.fcoefs_mu[i, :],\n",
    "                                gp.kernel.fcoefs_sig[i, :]):\n",
    "            filters[i, :] += amp * np.exp(-0.5*((wavs-mu)/sig)**2)\n",
    "            \n",
    "    return residuals, fac, cov_C + cov_L, filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) model =  [[[4.08335391e-08 5.69870921e-08 1.23554002e-07 2.95768697e-07\n",
      "   1.06499099e-06 2.33056421e-06]\n",
      "  [2.62617363e-07 6.35391899e-07 1.10692806e-06 1.47496133e-06\n",
      "   1.92541459e-06 2.90221283e-06]\n",
      "  [9.46005221e-07 1.78668013e-06 2.54944804e-06 2.88478779e-06\n",
      "   3.59423529e-06 4.55089092e-06]\n",
      "  [2.65290439e-06 3.34813087e-06 3.89284878e-06 4.57019483e-06\n",
      "   5.17024858e-06 5.61131911e-06]\n",
      "  [5.06400673e-06 6.30706609e-06 6.28341113e-06 6.97195853e-06\n",
      "   7.01485264e-06 8.17838698e-06]\n",
      "  [2.49729655e-06 3.66992970e-06 4.55124566e-06 4.80477648e-06\n",
      "   5.13080182e-06 5.86229641e-06]\n",
      "  [1.21392911e-05 1.24088412e-05 1.18461666e-05 1.10777072e-05\n",
      "   1.06195590e-05 9.94736762e-06]\n",
      "  [2.76515781e-05 2.51054650e-05 2.24649885e-05 1.93983820e-05\n",
      "   1.71373027e-05 1.55420521e-05]]]\n",
      "1) fluxes =  [2.65789195 3.54284328 3.78797459 4.72882801 4.98432297 5.56413967]\n",
      "z =  1.9722299138465411\n",
      "ellMLs.shape =  (1, 8) ellMLs =  [[3361366.9044535  2798192.02288809 1548847.90387552 1003906.17209946\n",
      "   609578.93622242  952539.23489057  309828.00728125  146166.37794957]]\n",
      "bestType =  3\n",
      "X.shape =  (6, 3)  X = [[0.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [1.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [2.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [3.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [4.00000000e+00 1.97222991e+00 1.00390617e+06]\n",
      " [5.00000000e+00 1.97222991e+00 1.00390617e+06]]\n",
      "2) model_mean =  [[1.16617533e+05 2.33977154e+05 3.33536471e+05 3.60090579e+05\n",
      "  4.56529876e+05 5.30184260e+05]\n",
      " [2.83925755e+04 5.79456750e+04 8.25894645e+04 8.93078200e+04\n",
      "  1.12266263e+05 1.31896800e+05]\n",
      " [1.18813868e+04 2.45972566e+04 3.49838414e+04 3.81290679e+04\n",
      "  4.73156632e+04 5.62462582e+04]\n",
      " ...\n",
      " [6.41283187e-01 1.60342668e+00 2.00082072e+00 2.43991956e+00\n",
      "  2.51556309e+00 2.81390555e+00]\n",
      " [6.22421219e-01 1.59403952e+00 1.98512229e+00 2.43213078e+00\n",
      "  2.49609351e+00 2.79989462e+00]\n",
      " [6.03699536e-01 1.58469955e+00 1.97017163e+00 2.42369654e+00\n",
      "  2.47665333e+00 2.78469549e+00]]\n",
      "2) fluxes =  [2.65789195 3.54284328 3.78797459 4.72882801 4.98432297 5.56413967]\n",
      "nwalker= 0  p0[i]= [2.57254118 3.17714598 3.90653259 3.65109046 5.28573608 5.10830871\n",
      " 5.09453419 6.58880253 5.10058904 6.17929451]  :::  -19.98359234850708\n",
      "nwalker= 1  p0[i]= [2.57213892 3.1769466  3.90652993 3.65123662 5.2859491  5.10849729\n",
      " 5.09463385 6.58880306 5.10053336 6.17886551]  :::  -19.999908495950063\n",
      "nwalker= 2  p0[i]= [2.57212033 3.17677329 3.90614887 3.65066005 5.28523094 5.10770008\n",
      " 5.09380595 6.5879719  5.09970968 6.17817922]  :::  -19.93778549940654\n",
      "nwalker= 3  p0[i]= [2.5718397  3.17665063 3.90621506 3.65089243 5.28557773 5.108109\n",
      " 5.09424338 6.58842536 5.10017542 6.17865359]  :::  -19.97426598349663\n",
      "nwalker= 4  p0[i]= [2.57272732 3.1773231  3.90661913 3.65102782 5.28548372 5.10784151\n",
      " 5.09385734 6.58797064 5.09970056 6.17825747]  :::  -19.939101938362437\n",
      "nwalker= 5  p0[i]= [2.57206709 3.1767549  3.90620947 3.65081192 5.28545836 5.10797585\n",
      " 5.09410897 6.58829641 5.10006378 6.17855293]  :::  -19.960725614000783\n",
      "nwalker= 6  p0[i]= [2.57267255 3.17723022 3.90653757 3.65102352 5.2856244  5.10817665\n",
      " 5.09439824 6.58867795 5.10048796 6.17888753]  :::  -19.9718972922834\n",
      "nwalker= 7  p0[i]= [2.57228465 3.17688872 3.90623644 3.65073369 5.2853017  5.10777519\n",
      " 5.09388063 6.58802428 5.09970818 6.17795283]  :::  -19.940350553091488\n",
      "nwalker= 8  p0[i]= [2.57184697 3.17645853 3.90580797 3.65030924 5.28490043 5.10743661\n",
      " 5.0936585  6.58796846 5.09984009 6.17820079]  :::  -19.926983867090645\n",
      "nwalker= 9  p0[i]= [2.57221424 3.17692678 3.90636313 3.65090827 5.2854755  5.10790377\n",
      " 5.09393525 6.58800021 5.09962346 6.17797602]  :::  -19.948423227575812\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Initial state has a large condition number. Make sure that your walkers are linearly independent for the best performance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9676/3859867229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob,\n\u001b[1;32m    110\u001b[0m                                                 args=[sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms])\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Intern2022_PhotoZ/railenv/lib/python3.9/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36mrun_mcmc\u001b[0;34m(self, initial_state, nsteps, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Intern2022_PhotoZ/railenv/lib/python3.9/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress, progress_kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mwalkers_independent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         ):\n\u001b[0;32m--> 312\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0;34m\"Initial state has a large condition number. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;34m\"Make sure that your walkers are linearly independent for the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Initial state has a large condition number. Make sure that your walkers are linearly independent for the best performance"
     ]
    }
   ],
   "source": [
    "numZ = redshiftGrid.size\n",
    "all_z = np.zeros((numObjectsTraining, ))\n",
    "all_fluxes = np.zeros((numObjectsTraining, numBands))\n",
    "all_fluxes_var = np.zeros((numObjectsTraining, numBands))\n",
    "all_bestTypes = np.zeros((numObjectsTraining, ), dtype=int)\n",
    "all_model_mean = np.zeros((numZ, numObjectsTraining, numBands))\n",
    "all_model_covar = np.zeros((numZ, numObjectsTraining, numBands))\n",
    "\n",
    "loc = - 1\n",
    "trainingDataIter1 = getDataFromFile(params, 0, numObjectsTraining,prefix=\"training_\", getXY=True,CV=True)\n",
    "\n",
    "# loop on training data\n",
    "\n",
    "for z, normedRefFlux,\\\n",
    "    bands, fluxes, fluxesVar,\\\n",
    "    bandsCV, fluxesCV, fluxesVarCV,\\\n",
    "        X, Y, Yvar in trainingDataIter1:\n",
    "    loc += 1\n",
    "\n",
    "    themod = np.zeros((1, f_mod.shape[0], bands.size))\n",
    "    \n",
    "    # loop on templates\n",
    "    for it in range(f_mod.shape[0]):\n",
    "        for ib, band in enumerate(bands):\n",
    "            themod[0, it, ib] = f_mod[it, band](z)\n",
    "            \n",
    "    # compute  the likelihood        \n",
    "    chi2_grid, ellMLs = scalefree_flux_likelihood(fluxes, fluxesVar, themod, returnChi2=True)\n",
    "    \n",
    "    \n",
    "    print(\"1) model = \", themod)\n",
    "    print(\"1) fluxes = \",fluxes)\n",
    "    \n",
    "    \n",
    "    print(\"z = \",z)\n",
    "    \n",
    "    print(\"ellMLs.shape = \",ellMLs.shape, \"ellMLs = \",ellMLs)\n",
    "    \n",
    "    bestType = np.argmin(chi2_grid)\n",
    "    \n",
    "    print(\"bestType = \",bestType)\n",
    "    \n",
    "    ell = ellMLs[0, bestType]\n",
    "    #ell2 = normedRefFlux * 4 * np.pi * (DL(z)**2. * (1+z)) / params['fluxLuminosityNorm']\n",
    "    \n",
    "    # fit the gaussian process\n",
    "    X[:, 2] = ell\n",
    "    \n",
    "    print(\"X.shape = \",X.shape, \" X =\", X)\n",
    "    \n",
    "    gp.setData(X, Y, Yvar, bestType)\n",
    "    model_mean, model_covar = gp.predictAndInterpolate(redshiftGrid, ell=ell)\n",
    "    all_model_mean[:, loc, :], all_model_covar[:, loc, :] = model_mean, model_covar\n",
    "\n",
    "    print(\"2) model_mean = \",model_mean)\n",
    "    print(\"2) fluxes = \",fluxes)\n",
    "    \n",
    "    \n",
    "    all_z[loc] = z\n",
    "    all_bestTypes[loc] = bestType\n",
    "    all_fluxes[loc, bands] = fluxes\n",
    "    all_fluxes_var[loc, bands] = fluxesVar\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if loc < 10:\n",
    "        if True:\n",
    "            fac = ell * (1+z)**2. / DL(z)**2. / (4*np.pi) * 1e4/2.3\n",
    "            sedtf = sed_interps[bestType](wavs/(1+z)) * fac\n",
    "            sedtf_hi = sed_interps[bestType](wavs_hi/(1+z)) * fac\n",
    "\n",
    "            if True:\n",
    "                residuals, fac, cov, filters = drawSEDresiduals(gp, z, ell, wavs)\n",
    "                residuals_hi, fac_hi, cov_hi, filters_hi = drawSEDresiduals(gp, z, ell, wavs_hi)\n",
    "                filternorms = [np.trapz(filters_hi[ib], x=wavs_hi) for i, ib in enumerate(bands)]\n",
    "                sed = np.random.uniform(wavs.size) * wavs\n",
    "                #icov = np.linalg.inv(cov)\n",
    "                det = np.linalg.det(cov)\n",
    "                \n",
    "                def lnprob(sed, sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms):\n",
    "                    sedfluxes = np.zeros((bands.size, ))\n",
    "                    sed_hi = interp1d(wavs, sed, kind='cubic')(wavs_hi)#np.interp(wavs_hi, wavs, sed)\n",
    "                    for i, ib in enumerate(bands):\n",
    "                        sedfluxes[i] = np.trapz(filters_hi[ib]*sed_hi, x=wavs_hi) / filternorms[i]\n",
    "                    lp = np.sum(-0.5*(sedfluxes - fluxes)**2/fluxesVar) #- 0.5 * np.prod(np.log(fluxesVar))\n",
    "                    res = (sed - sedtf) / fac\n",
    "                    #print(lp,  np.sum(-0.5*np.dot(res, np.linalg.solve(cov, res))), end=\" \")\n",
    "                    #lp += np.sum(-0.5*np.dot(res, np.linalg.solve(cov, res))) \n",
    "                    return lp\n",
    "                ndim = wavs.size\n",
    "                #nwalkers = ndim * 10\n",
    "                nwalkers =  10\n",
    "                \n",
    "                #ndim, nwalkers = 5, 100\n",
    "                #ivar = 1. / np.random.rand(ndim)\n",
    "                #p0 = np.random.randn(nwalkers, ndim)\n",
    "                #sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[ivar])\n",
    "                #sampler.run_mcmc(p0, 10000)\n",
    "                \n",
    "                ymax = fluxes.max() * 1.2\n",
    "                ymin = fluxes.min() / 2\n",
    "                p0 = np.random.uniform(low=ymin, high=ymax, size=ndim * nwalkers).reshape((nwalkers, ndim))\n",
    "                for i in range(nwalkers):\n",
    "                    p0[i] = 1*sedtf + fac * np.random.multivariate_normal(0*wavs, cov)\n",
    "                    print(\"nwalker=\",i,\" p0[i]=\",p0[i],\" ::: \",lnprob(p0[i], sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms))\n",
    "                #stop\n",
    "                sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob,\n",
    "                                                args=[sedtf, fac, fluxes, bands, wavs, wavs_hi, cov, det, filters_hi, filternorms])\n",
    "                pos, prob, state = sampler.run_mcmc(p0, 20,progress=True)\n",
    "                sampler.reset()\n",
    "                sampler.run_mcmc(pos, 20,progress=True)\n",
    "                print(\"Mean acceptance fraction: {0:.3f}\"\n",
    "                        .format(np.mean(sampler.acceptance_fraction)))\n",
    "                seds = sampler.flatchain\n",
    "                sedmean, sedstd = seds.mean(axis=0), seds.std(axis=0)\n",
    "                sedmean_hi = interp1d(wavs, sedmean, kind='cubic')(wavs_hi)\n",
    "                sedstd_hi = interp1d(wavs, sedstd, kind='cubic')(wavs_hi)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "            #ax.plot(wavs, sedtf, 'k')\n",
    "            ax.plot(wavs_hi, sedtf_hi, c=colTF, label='Standard template fitting') \n",
    "            ax.plot(wavs_hi, sedmean_hi, color=colGP, label='New method')\n",
    "            ax.fill_between(wavs_hi, sedmean_hi+sedstd_hi, sedmean_hi-sedstd_hi, color=colGP, alpha=0.4)\n",
    "            \n",
    "            \n",
    "            #ax.fill_between(wavs, sedmean+sedstd, sedmean-sedstd, color='b', alpha=0.2)\n",
    "            #for w in wavs:\n",
    "            #    ax.axvline(w, c='gray', alpha=0.5, lw=0.5)\n",
    "            #for i in range(seds.shape[0]):\n",
    "            #    ax.plot(wavs_hi, interp1d(wavs, seds[i, :], kind='cubic')(wavs_hi), c='gray', alpha=0.2, lw=0.3)\n",
    "            ax.errorbar(bandwavelengths[bands, 0], fluxes, \n",
    "                        xerr=bandwavelengths[bands, 1], yerr=np.sqrt(fluxesVar),\n",
    "                       fmt='o', c='k', markersize=5, label='Deep training photometry')\n",
    "            ax.errorbar(bandwavelengths[bandsCV, 0], fluxesCV, \n",
    "                        xerr=bandwavelengths[bandsCV, 1], yerr=np.sqrt(fluxesVarCV),\n",
    "                       fmt='s', c='b', markersize=5, label='Shallow testing photometry')\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_ylabel(r'$L_\\nu(\\lambda)$')\n",
    "            #ax.set_yticks(np.linspace(10**-5, 10**-4, 10))\n",
    "            ax.set_xlabel(r'$\\lambda$ [$\\AA$]')\n",
    "            ax.set_xlim([lamMin, lamMax])\n",
    "            ax.set_xticks(np.linspace(4e3, 1e4, 7))\n",
    "            ax.set_xticklabels(np.linspace(4e3, 1e4, 7))\n",
    "            ax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "            #ax.set_ylim([0.5*np.min(sedtf), 2.5*np.max(sedtf)])\n",
    "            ax.legend(ncol=2, frameon=False, loc='upper left')\n",
    "            fig.tight_layout()\n",
    "            fig.savefig('./figures/showcase/traininggalaxy_fnulambda-'+str(loc)+'.pdf')\n",
    "            \n",
    "        if False:\n",
    "            fig, axs = plt.subplots(4, numBands//4, figsize=(12, 6), sharex=True, sharey=True)\n",
    "            for i in range(numBands//4):\n",
    "                axs[-1, i].set_xlabel('Redshift')\n",
    "            for i in range(4):\n",
    "                axs[i, 0].set_ylabel('Flux')\n",
    "            axs = axs.ravel()\n",
    "            temp = np.concatenate([ell*f_mod[bestType, i](redshiftGrid)*redshiftGrid**2\n",
    "                                   for i, bnm in enumerate(bandNames)])\n",
    "            axs[-1].set_ylim([0.5*np.min(temp), 2*np.max(temp)])\n",
    "            for i, bnm in enumerate(bandNames):\n",
    "                axs[i].text(0.1, 0.8*np.max(temp), bnm.replace('_', ' '))\n",
    "                axs[i].plot(redshiftGrid, ell*f_mod[bestType, i](redshiftGrid)*redshiftGrid**2,\n",
    "                            c=colTF, label='Standard template fitting', ls='dashed', zorder=2)\n",
    "                axs[i].plot(redshiftGrid, model_mean[:, i]*redshiftGrid**2,\n",
    "                            c=colGP, label='New method', zorder=1)#, label=bnm.replace('_', ' '))\n",
    "                axs[i].fill_between(redshiftGrid, \n",
    "                                    (model_mean[:, i]-np.sqrt(model_covar[:, i]))*redshiftGrid**2, \n",
    "                                    (model_mean[:, i]+np.sqrt(model_covar[:, i]))*redshiftGrid**2,\n",
    "                                    color=colGP, alpha=0.4, zorder=0)\n",
    "                if i in bands:\n",
    "                    pos = list(bands).index(i)\n",
    "                    axs[i].errorbar(z, fluxes[pos]*z**2, yerr=np.sqrt(fluxesVar[pos])*z**2, c='k', markersize=5, fmt='o')\n",
    "                if i in bandsCV:\n",
    "                    pos = list(bandsCV).index(i)\n",
    "                    axs[i].errorbar(z, fluxesCV[pos]*z**2, yerr=np.sqrt(fluxesVarCV[pos])*z**2, c='b', markersize=5, fmt='s')\n",
    "                #axs[i].set_ylim([np.min(model_mean), np.max(model_mean)])\n",
    "                axs[i].set_xticks([0, 0.5, 1.0])\n",
    "            axs[0].legend(ncol=3, frameon=False, loc='upper left', bbox_to_anchor=(0.0, 1.4))\n",
    "            axs[-1].set_yscale('log')\n",
    "            axs[-1].set_xlim([0, 1.5])\n",
    "            fig.subplots_adjust(wspace=0, hspace=0)\n",
    "            fig.savefig('./figures/showcase/traininggalaxy_fluxredshiftmodel-'+str(loc)+'.pdf')\n",
    "            \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the redshift / photometric model\n",
    "dir_seds = params['templates_directory']\n",
    "dir_filters = params['bands_directory']\n",
    "lambdaRef = params['lambdaRef']\n",
    "sed_names = params['templates_names']\n",
    "f_mod_grid = np.zeros((redshiftGrid.size, len(sed_names),\n",
    "                  len(params['bandNames'])))\n",
    "for t, sed_name in enumerate(sed_names):\n",
    "    f_mod_grid[:, t, :] = np.loadtxt(dir_seds + '/' + sed_name +\n",
    "                                '_fluxredshiftmod.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run that to look at redshift PDFs\n",
    "p_t = params['p_t'][all_bestTypes][None, :]\n",
    "p_z_t = params['p_z_t'][all_bestTypes][None, :]\n",
    "prior = np.exp(-0.5*((redshiftGrid[:, None]-all_z[None, :])/params['zPriorSigma'])**2)\n",
    "Ncompress = params['Ncompress']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 2.5), sharey=True)\n",
    "\n",
    "loc = -1\n",
    "targetDataIter = getDataFromFile(params, 0, numObjectsTraining,\n",
    "                                 prefix=\"target_\", getXY=False)\n",
    "for z, normedRefFlux, bands, fluxes, fluxesVar, bCV, fCV, fvCV in targetDataIter:\n",
    "    loc += 1\n",
    "    if loc < 100:\n",
    "        fulllike_grid = np.zeros((all_model_mean.shape[0], all_model_mean.shape[1]))\n",
    "        ell_hat_z = normedRefFlux * 4 * np.pi\\\n",
    "            * params['fluxLuminosityNorm'] \\\n",
    "            * (DL(redshiftGrid)**2. * (1+redshiftGrid))\n",
    "        ell_hat_z[:] = 1.0\n",
    "        params['ellPriorSigma'] = 0.2\n",
    "        approx_flux_likelihood_cy(fulllike_grid,\n",
    "            all_model_mean.shape[0], all_model_mean.shape[1], bands.size,\n",
    "            fluxes, fluxesVar, all_model_mean[:, :, bands],\n",
    "            all_model_covar[:, :, bands], \n",
    "            ell_hat_z, (ell_hat_z*params['ellPriorSigma'])**2\n",
    "        )\n",
    "        fulllike_grid *= prior\n",
    "        evidences = np.trapz(fulllike_grid, x=redshiftGrid, axis=0)\n",
    "        sortind = np.argsort(evidences)[::-1][0:Ncompress]\n",
    "        like_grid = fulllike_grid.sum(axis=1)\n",
    "        like_grid_comp = fulllike_grid[:, sortind].sum(axis=1)\n",
    "        alllike_grid_cww = np.zeros((f_mod_grid.shape[0], f_mod_grid.shape[1]))\n",
    "        params['ellPriorSigma'] = 1e12\n",
    "        approx_flux_likelihood_cy(alllike_grid_cww,\n",
    "            f_mod_grid.shape[0], f_mod_grid.shape[1], bands.size,\n",
    "            fluxes, fluxesVar, f_mod_grid[:, :, bands], 0*f_mod_grid[:, :, bands], \n",
    "            ell_hat_z, (ell_hat_z*params['ellPriorSigma'])**2\n",
    "        )\n",
    "        b_in = np.array(params['p_t'])[None, :]\n",
    "        beta2 = np.array(params['p_z_t'])**2.0\n",
    "        p_z = b_in * redshiftGrid[:, None] * np.exp(-0.5 * redshiftGrid[:, None]**2 / beta2[None, :]) / beta2[None, :]\n",
    "        alllike_grid_cww *= p_z\n",
    "        besttype = np.argmax(alllike_grid_cww.sum(axis=0))\n",
    "        like_grid_cww = alllike_grid_cww.sum(axis=1)  # [:, besttype]\n",
    "        if like_grid.sum() > 0:\n",
    "            zphotmean = np.average(redshiftGrid, weights=like_grid)\n",
    "            if zphotmean > 0.0 and zphotmean < 2.5 and z < 2.8:\n",
    "\n",
    "                for ax in axs:\n",
    "                    ax.cla()\n",
    "                for ii in sortind:\n",
    "                    axs[1].plot(redshiftGrid, fulllike_grid[:, ii], c='gray', lw=1, alpha=0.6)\n",
    "                axs[0].plot(redshiftGrid, like_grid, c=colGP, lw=2, label='New method')\n",
    "                like_grid_cww = like_grid_cww * np.max(like_grid) / np.max(like_grid_cww)\n",
    "                axs[0].plot(redshiftGrid, like_grid_cww, c=colTF, lw=2, label='Standard template fitting')\n",
    "                axs[1].plot(redshiftGrid, like_grid_comp, c=colGP, lw=2, label='Compressed new method')\n",
    "                axs[0].axvline(z, c='k', lw=1, ls='dashed', label='True redshift')\n",
    "                axs[1].axvline(z, c='k', lw=1, ls='dashed')\n",
    "                axs[0].set_ylabel(r'$p(z | \\hat{\\mathbf{F}})$')\n",
    "                axs[1].set_xlabel('Redshift')\n",
    "                thegr = np.concatenate((redshiftGrid[np.logical_and(like_grid_cww > 0.01, like_grid > 0.01)],\n",
    "                                 all_z[sortind]))    \n",
    "                axs[1].set_xlim([np.min(thegr), np.max(thegr)])\n",
    "                axs[0].set_xlim([np.min(thegr), np.max(thegr)])\n",
    "                axs[0].set_xlabel('Redshift')\n",
    "                ylimax = 1.2*np.max(np.concatenate((like_grid, like_grid_cww)))\n",
    "                axs[0].set_ylim([0, ylimax])\n",
    "                for iioff, ii in enumerate(sortind):\n",
    "                    if iioff == 0:\n",
    "                        lb = 'Training galaxies'\n",
    "                    else:\n",
    "                        lb = None\n",
    "                    axs[1].scatter(all_z[ii], ylimax*0.99, c='gray', marker='x', lw=2, s=10, label=lb)\n",
    "                axs[0].yaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "                axs[0].legend(loc='upper right', frameon=False, ncol=2, bbox_to_anchor=(1.0, 1.35))\n",
    "                axs[0].set_yticks([])\n",
    "                axs[1].legend(loc='upper right', frameon=False, ncol=1, bbox_to_anchor=(0.8, 1.35))\n",
    "                axs[1].set_yticks([])\n",
    "                #fig.tight_layout()\n",
    "                fig.subplots_adjust(wspace=0, hspace=0, bottom=0.2, top=0.8, left=0.05, right=0.95)\n",
    "                fig.savefig('./figures/showcases/data-pdfs-'+str(loc)+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
