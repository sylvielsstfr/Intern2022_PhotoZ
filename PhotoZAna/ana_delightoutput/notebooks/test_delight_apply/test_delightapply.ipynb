{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "industrial-chile",
   "metadata": {},
   "source": [
    "# Test Delight Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-green",
   "metadata": {},
   "source": [
    "- author : Sylvie Dagoret-Campagne\n",
    "\n",
    "- affiliation : IJCLab/IN2P3/CNRS\n",
    "- creation date : March 17th 2021\n",
    "- update : April 4th 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from delight.io import *\n",
    "from delight.utils import *\n",
    "from delight.photoz_gp import PhotozGP\n",
    "from delight.utils_cy import approx_flux_likelihood_cy\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reported-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "from delight.photoz_kernels import Photoz_mean_function, Photoz_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "occupied-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "coloredlogs.install(level='DEBUG', logger=logger,fmt='%(asctime)s,%(msecs)03d %(programname)s, %(name)s[%(process)d] %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bottom-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "plt.rcParams[\"axes.labelsize\"] = 'xx-large'\n",
    "plt.rcParams['axes.titlesize'] = 'xx-large'\n",
    "plt.rcParams['xtick.labelsize']= 'xx-large'\n",
    "plt.rcParams['ytick.labelsize']= 'xx-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-duncan",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "- select if want to control Delight internal simulation or DC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "swedish-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_DC2=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "convinced-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_DC2:\n",
    "    configfilename='tmp/parametersTest.cfg'\n",
    "else:\n",
    "    configfilename='tmpsim/parametersTest.cfg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-absence",
   "metadata": {},
   "source": [
    "# Load config and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "impaired-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-07 18:48:59,311 ipykernel_launcher.py, __main__[399] INFO --- DELIGHT-APPLY ---\n"
     ]
    }
   ],
   "source": [
    "params = parseParamFile(configfilename, verbose=False)\n",
    "\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "threadNum = comm.Get_rank()\n",
    "numThreads = comm.Get_size()\n",
    "\n",
    "\n",
    "if threadNum == 0:\n",
    "    #print(\"--- DELIGHT-APPLY ---\")\n",
    "    logger.info(\"--- DELIGHT-APPLY ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statistical-surface",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fb80f87d440b>:23: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  numObjectsTraining = np.sum(1 for line in open(params['training_catFile']))\n",
      "<ipython-input-8-fb80f87d440b>:24: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  numObjectsTarget = np.sum(1 for line in open(params['target_catFile']))\n",
      "2021-04-07 18:48:59,489 ipykernel_launcher.py, __main__[399] INFO Number of Training Objects 3755\n",
      "2021-04-07 18:48:59,490 ipykernel_launcher.py, __main__[399] INFO Number of Target Objects 10692\n",
      "2021-04-07 18:48:59,491 ipykernel_launcher.py, __main__[399] INFO Thread 0 , analyzes lines 0 to 10692\n"
     ]
    }
   ],
   "source": [
    " # Read filter coefficients, compute normalization of filters\n",
    "bandCoefAmplitudes, bandCoefPositions, bandCoefWidths, norms = readBandCoefficients(params)\n",
    "numBands = bandCoefAmplitudes.shape[0]\n",
    "\n",
    "redshiftDistGrid, redshiftGrid, redshiftGridGP = createGrids(params)\n",
    "f_mod_interp = readSEDs(params)\n",
    "nt = f_mod_interp.shape[0]\n",
    "nz = redshiftGrid.size\n",
    "\n",
    "dir_seds = params['templates_directory']\n",
    "dir_filters = params['bands_directory']\n",
    "lambdaRef = params['lambdaRef']\n",
    "sed_names = params['templates_names']\n",
    "f_mod_grid = np.zeros((redshiftGrid.size, len(sed_names),len(params['bandNames'])))\n",
    "\n",
    "\n",
    "for t, sed_name in enumerate(sed_names):\n",
    "    f_mod_grid[:, t, :] = np.loadtxt(dir_seds + '/' + sed_name +'_fluxredshiftmod.txt')\n",
    "\n",
    "numZbins = redshiftDistGrid.size - 1\n",
    "numZ = redshiftGrid.size\n",
    "\n",
    "numObjectsTraining = np.sum(1 for line in open(params['training_catFile']))\n",
    "numObjectsTarget = np.sum(1 for line in open(params['target_catFile']))\n",
    "redshiftsInTarget = ('redshift' in params['target_bandOrder'])\n",
    "Ncompress = params['Ncompress']\n",
    "\n",
    "firstLine = int(threadNum * numObjectsTarget / float(numThreads))\n",
    "lastLine = int(min(numObjectsTarget,(threadNum + 1) * numObjectsTarget / float(numThreads)))\n",
    "numLines = lastLine - firstLine\n",
    "\n",
    "if threadNum == 0:\n",
    "    msg= 'Number of Training Objects ' +  str(numObjectsTraining)\n",
    "    logger.info(msg)\n",
    "\n",
    "    msg='Number of Target Objects ' + str(numObjectsTarget)\n",
    "    logger.info(msg)\n",
    "\n",
    "comm.Barrier()\n",
    "\n",
    "msg= 'Thread '+ str(threadNum) + ' , analyzes lines ' +  str(firstLine) + ' to ' + str( lastLine)\n",
    "logger.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "signed-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = approx_DL()\n",
    "gp = PhotozGP(f_mod_interp,\\\n",
    "              bandCoefAmplitudes, bandCoefPositions, bandCoefWidths,\\\n",
    "              params['lines_pos'], params['lines_width'],\\\n",
    "              params['V_C'], params['V_L'],\\\n",
    "              params['alpha_C'], params['alpha_L'],\\\n",
    "              redshiftGridGP, use_interpolators=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stunning-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local files to store results\n",
    "numMetrics = 7 + len(params['confidenceLevels'])\n",
    "localPDFs = np.zeros((numLines, numZ))\n",
    "localMetrics = np.zeros((numLines, numMetrics))\n",
    "localCompressIndices = np.zeros((numLines,  Ncompress), dtype=int)\n",
    "localCompEvidences = np.zeros((numLines,  Ncompress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-baseball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.0093302726745605 0.3276803493499756 0.07976293563842773\n"
     ]
    }
   ],
   "source": [
    "# Looping over chunks of the training set to prepare model predictions over z\n",
    "numChunks = params['training_numChunks']\n",
    "for chunk in range(numChunks):\n",
    "    TR_firstLine = int(chunk * numObjectsTraining / float(numChunks))\n",
    "    TR_lastLine = int(min(numObjectsTraining, (chunk + 1) * numObjectsTarget / float(numChunks)))\n",
    "    targetIndices = np.arange(TR_firstLine, TR_lastLine)\n",
    "    numTObjCk = TR_lastLine - TR_firstLine\n",
    "    redshifts = np.zeros((numTObjCk, ))\n",
    "    model_mean = np.zeros((numZ, numTObjCk, numBands))\n",
    "    model_covar = np.zeros((numZ, numTObjCk, numBands))\n",
    "    bestTypes = np.zeros((numTObjCk, ), dtype=int)\n",
    "    ells = np.zeros((numTObjCk, ), dtype=int)\n",
    "\n",
    "    loc = TR_firstLine - 1\n",
    "    trainingDataIter = getDataFromFile(params, TR_firstLine, TR_lastLine,prefix=\"training_\", ftype=\"gpparams\")\n",
    "\n",
    "    # loop o training data and training GP coefficient \n",
    "    for loc, (z, ell, bands, X, B, flatarray) in enumerate(trainingDataIter):\n",
    "        t1 = time()\n",
    "        redshifts[loc] = z\n",
    "        gp.setCore(X, B, nt,flatarray[0:nt+B+B*(B+1)//2])\n",
    "        bestTypes[loc] = gp.bestType\n",
    "        ells[loc] = ell\n",
    "        model_mean[:, loc, :], model_covar[:, loc, :] = gp.predictAndInterpolate(redshiftGrid, ell=ell)\n",
    "        t2 = time()\n",
    "        # print(loc, t2-t1)\n",
    "\n",
    "    # p_t = params['p_t'][bestTypes][None, :]\n",
    "    # p_z_t = params['p_z_t'][bestTypes][None, :]\n",
    "    prior = np.exp(-0.5*((redshiftGrid[:, None]-redshifts[None, :]) /params['zPriorSigma'])**2)\n",
    "    # prior[prior < 1e-6] = 0\n",
    "    # prior *= p_t * redshiftGrid[:, None] *\n",
    "    # np.exp(-0.5 * redshiftGrid[:, None]**2 / p_z_t) / p_z_t\n",
    "\n",
    "    if params['useCompression'] and params['compressionFilesFound']:\n",
    "        fC = open(params['compressMargLikFile'])\n",
    "        fCI = open(params['compressIndicesFile'])\n",
    "        itCompM = itertools.islice(fC, firstLine, lastLine)\n",
    "        iterCompI = itertools.islice(fCI, firstLine, lastLine)\n",
    "\n",
    "    targetDataIter = getDataFromFile(params, firstLine, lastLine,prefix=\"target_\", getXY=False, CV=False)\n",
    "    # loop on target \n",
    "    for loc, (z, normedRefFlux, bands, fluxes, fluxesVar, bCV, dCV, dVCV) in enumerate(targetDataIter):\n",
    "        t1 = time()\n",
    "        ell_hat_z = normedRefFlux * 4 * np.pi * params['fluxLuminosityNorm'] * (DL(redshiftGrid)**2. * (1+redshiftGrid))\n",
    "        ell_hat_z[:] = 1\n",
    "        if params['useCompression'] and params['compressionFilesFound']:\n",
    "            indices = np.array(next(iterCompI).split(' '), dtype=int)\n",
    "            sel = np.in1d(targetIndices, indices, assume_unique=True)\n",
    "            \n",
    "            like_grid2 = approx_flux_likelihood(fluxes,fluxesVar,model_mean[:, sel, :][:, :, bands],\\\n",
    "            f_mod_covar=model_covar[:, sel, :][:, :, bands],\\\n",
    "            marginalizeEll=True, normalized=False,\\\n",
    "            ell_hat=ell_hat_z,\\\n",
    "            ell_var=(ell_hat_z*params['ellPriorSigma'])**2)\n",
    "            \n",
    "            like_grid *= prior[:, sel]\n",
    "        else:\n",
    "            like_grid = np.zeros((nz, model_mean.shape[1]))\n",
    "            approx_flux_likelihood_cy(\\\n",
    "                    like_grid, nz, model_mean.shape[1], bands.size,\\\n",
    "                    fluxes, fluxesVar,\\\n",
    "                    model_mean[:, :, bands],\\\n",
    "                    model_covar[:, :, bands],\\\n",
    "                    ell_hat=ell_hat_z,\\\n",
    "                    ell_var=(ell_hat_z*params['ellPriorSigma'])**2)\n",
    "            like_grid *= prior[:, :]\n",
    "        t2 = time()\n",
    "        localPDFs[loc, :] += like_grid.sum(axis=1)\n",
    "        evidences = np.trapz(like_grid, x=redshiftGrid, axis=0)\n",
    "        t3 = time()\n",
    "\n",
    "        if params['useCompression'] and not params['compressionFilesFound']:\n",
    "            if localCompressIndices[loc, :].sum() == 0:\n",
    "                sortind = np.argsort(evidences)[::-1][0:Ncompress]\n",
    "                localCompressIndices[loc, :] = targetIndices[sortind]\n",
    "                localCompEvidences[loc, :] = evidences[sortind]\n",
    "            else:\n",
    "                dind = np.concatenate((targetIndices,localCompressIndices[loc, :]))\n",
    "                devi = np.concatenate((evidences,localCompEvidences[loc, :]))\n",
    "                sortind = np.argsort(devi)[::-1][0:Ncompress]\n",
    "                localCompressIndices[loc, :] = dind[sortind]\n",
    "                localCompEvidences[loc, :] = devi[sortind]\n",
    "\n",
    "        if chunk == numChunks - 1\\\n",
    "                and redshiftsInTarget\\\n",
    "                and localPDFs[loc, :].sum() > 0:\n",
    "            localMetrics[loc, :] = computeMetrics(z, redshiftGrid,localPDFs[loc, :],params['confidenceLevels'])\n",
    "        t4 = time()\n",
    "        if loc % 100 == 0:\n",
    "            print(loc, t2-t1, t3-t2, t4-t3)\n",
    "\n",
    "    if params['useCompression'] and params['compressionFilesFound']:\n",
    "        fC.close()\n",
    "        fCI.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.Barrier()\n",
    "\n",
    "if threadNum == 0:\n",
    "    globalPDFs = np.zeros((numObjectsTarget, numZ))\n",
    "    globalCompressIndices = np.zeros((numObjectsTarget, Ncompress), dtype=int)\n",
    "    globalCompEvidences = np.zeros((numObjectsTarget, Ncompress))\n",
    "    globalMetrics = np.zeros((numObjectsTarget, numMetrics))\n",
    "else:\n",
    "    globalPDFs = None\n",
    "    globalCompressIndices = None\n",
    "    globalCompEvidences = None\n",
    "    globalMetrics = None\n",
    "\n",
    "firstLines = [int(k*numObjectsTarget/numThreads) for k in range(numThreads)]\n",
    "lastLines = [int(min(numObjectsTarget, (k+1)*numObjectsTarget/numThreads)) for k in range(numThreads)]\n",
    "numLines = [lastLines[k] - firstLines[k] for k in range(numThreads)]\n",
    "\n",
    "sendcounts = tuple([numLines[k] * numZ for k in range(numThreads)])\n",
    "displacements = tuple([firstLines[k] * numZ for k in range(numThreads)])\n",
    "comm.Gatherv(localPDFs,[globalPDFs, sendcounts, displacements, MPI.DOUBLE])\n",
    "\n",
    "sendcounts = tuple([numLines[k] * Ncompress for k in range(numThreads)])\n",
    "displacements = tuple([firstLines[k] * Ncompress for k in range(numThreads)])\n",
    "comm.Gatherv(localCompressIndices,[globalCompressIndices, sendcounts, displacements, MPI.LONG])\n",
    "comm.Gatherv(localCompEvidences,[globalCompEvidences, sendcounts, displacements, MPI.DOUBLE])\n",
    "comm.Barrier()\n",
    "\n",
    "sendcounts = tuple([numLines[k] * numMetrics for k in range(numThreads)])\n",
    "displacements = tuple([firstLines[k] * numMetrics for k in range(numThreads)])\n",
    "comm.Gatherv(localMetrics,[globalMetrics, sendcounts, displacements, MPI.DOUBLE])\n",
    "\n",
    "comm.Barrier()\n",
    "\n",
    "if threadNum == 0:\n",
    "    fmt = '%.2e'\n",
    "    fname = params['redshiftpdfFileComp'] if params['compressionFilesFound'] else params['redshiftpdfFile']\n",
    "    np.savetxt(fname, globalPDFs, fmt=fmt)\n",
    "    if redshiftsInTarget:\n",
    "        np.savetxt(params['metricsFile'], globalMetrics, fmt=fmt)\n",
    "    if params['useCompression'] and not params['compressionFilesFound']:\n",
    "        np.savetxt(params['compressMargLikFile'],globalCompEvidences, fmt=fmt)\n",
    "        np.savetxt(params['compressIndicesFile'],globalCompressIndices, fmt=\"%i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-purse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
